{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel, LdaMulticore, TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import spacy\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import gensim\n",
    "import string\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "def preprocessing(raw_text):\n",
    "    # lowercasing, stemming and removing stop words\n",
    "    sw = stopwords.words('english')\n",
    "    sw2 = ['be', 'go', 'can', 'also', 'just', 'would', 'could']\n",
    "    eng_re = re.compile(r'^[a-zA-Z]*$')\n",
    "    words = []\n",
    "    for w in raw_text.lower().split():\n",
    "        # remove stop words\n",
    "        if not w in sw:\n",
    "            # remove non-ascii characters\n",
    "            s = re.sub(r'[^\\x00-\\x7f]', r'', w)\n",
    "            ss = re.sub(r'https?:\\/\\/.*', r'', s)\n",
    "            if ss != '':\n",
    "                words.append(ss)\n",
    "    doc = nlp(\" \".join(words))\n",
    "    words_lemmatized = [token.lemma_ for token in doc if token.pos_ in ['NOUN', 'ADJ', 'VERB', 'ADV']]\n",
    "    # remove some specific words, like \"breast\", \"cancer\", \"#\"\n",
    "    words_lemmatized2 = [x for x in words_lemmatized if (x not in [\"#\", \"-\", \"breast\", \"cancer\", \"breastcancer\"]) and \n",
    "                                                        (len(x) > 1) and \n",
    "                                                        (re.match(eng_re, x)) and\n",
    "                                                        (x not in sw2)]\n",
    "    return \" \".join(words_lemmatized2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"/Users/yhu245/Documents/GitHub/breast_cancer_analysis/\" #path saving unlabeled data\n",
    "path2 = \"/Users/yhu245/Dropbox/CS584-textmining/dwr4xn8kcv-3/\" #path saving word2vec model\n",
    "df_tweets = pd.read_csv(path1 + \"BreastCancer_Rawdata_TWs_unlabeled_predicted.csv\")\n",
    "df_reddit = pd.read_csv(path1 + \"q4_tw_rd/data/data_reddit_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df=df_tweets, tweet_col='text'):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # drop rows with empty values\n",
    "    df_copy.dropna(inplace=True)\n",
    "    \n",
    "    \n",
    "    # lower the tweets\n",
    "    df_copy['preprocessed_' + tweet_col] = df_copy[tweet_col].str.lower()\n",
    "    \n",
    "    # filter out stop words and URLs\n",
    "    df_copy['preprocessed_' + tweet_col] = df_copy['preprocessed_' + tweet_col].apply(lambda row: preprocessing(row))\n",
    "    #df_copy['preprocessed_' + tweet_col] = df_copy['preprocessed_' + tweet_col].apply(lambda row: tokenize(row))\n",
    "    #tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    #df_copy['tokenized_' + tweet_col] = df_copy['preprocessed_' + tweet_col].apply(lambda row: tokenizer.tokenize(row))\n",
    "    #df_copy['preprocessed_' + tweet_col] = df_copy['tokenized_text'].apply(lambda row: ' '.join(row))\n",
    "   \n",
    "    return df_copy\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddti Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>incredally07</td>\n",
       "      <td>1602699352</td>\n",
       "      <td>I just need to complain a little.  I got my la...</td>\n",
       "      <td>need complain little get last tissue expander ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookiebatter123</td>\n",
       "      <td>1602637885</td>\n",
       "      <td>My mum (50) has just been diagnosed with tripl...</td>\n",
       "      <td>diagnose triple negative doctor say next month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wonkishgardener</td>\n",
       "      <td>1602630055</td>\n",
       "      <td>3 days of radiation left (woo hoo!) and sudden...</td>\n",
       "      <td>day radiation left woo suddenly almost overnig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HonorableMention111</td>\n",
       "      <td>1602628724</td>\n",
       "      <td>Iâ€™ve been on chemo since the beginning of June...</td>\n",
       "      <td>have chemo begin final tomorrow think finally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Handy_Raccoon323</td>\n",
       "      <td>1602627408</td>\n",
       "      <td>Please excuse the formatting I'm on shitty mob...</td>\n",
       "      <td>excuse format shitty hubby doctor know punch b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id   timestamp  \\\n",
       "0         incredally07  1602699352   \n",
       "1      cookiebatter123  1602637885   \n",
       "2      wonkishgardener  1602630055   \n",
       "3  HonorableMention111  1602628724   \n",
       "4     Handy_Raccoon323  1602627408   \n",
       "\n",
       "                                                text  \\\n",
       "0  I just need to complain a little.  I got my la...   \n",
       "1  My mum (50) has just been diagnosed with tripl...   \n",
       "2  3 days of radiation left (woo hoo!) and sudden...   \n",
       "3  Iâ€™ve been on chemo since the beginning of June...   \n",
       "4  Please excuse the formatting I'm on shitty mob...   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  need complain little get last tissue expander ...  \n",
       "1  diagnose triple negative doctor say next month...  \n",
       "2  day radiation left woo suddenly almost overnig...  \n",
       "3  have chemo begin final tomorrow think finally ...  \n",
       "4  excuse format shitty hubby doctor know punch b...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddits_clean = clean_data(df_reddit)\n",
    "df_reddits_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_reddit = df_reddits_clean['preprocessed_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.55 s, sys: 463 ms, total: 4.01 s\n",
      "Wall time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(document_reddit)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df_reddit_tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaahhhhh</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abate</th>\n",
       "      <th>abcess</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abemaciclib</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablation</th>\n",
       "      <th>...</th>\n",
       "      <th>ysc</th>\n",
       "      <th>yup</th>\n",
       "      <th>zap</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoladex</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zometa</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7840 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaahhhhh  aback  abandon  abate  abcess  abdomen  abdominal  abemaciclib  \\\n",
       "0       0.0    0.0      0.0    0.0     0.0      0.0        0.0          0.0   \n",
       "1       0.0    0.0      0.0    0.0     0.0      0.0        0.0          0.0   \n",
       "2       0.0    0.0      0.0    0.0     0.0      0.0        0.0          0.0   \n",
       "3       0.0    0.0      0.0    0.0     0.0      0.0        0.0          0.0   \n",
       "4       0.0    0.0      0.0    0.0     0.0      0.0        0.0          0.0   \n",
       "\n",
       "   ability  ablation  ...  ysc  yup  zap  zip  zoladex  zoloft  zombie  \\\n",
       "0      0.0       0.0  ...  0.0  0.0  0.0  0.0      0.0     0.0     0.0   \n",
       "1      0.0       0.0  ...  0.0  0.0  0.0  0.0      0.0     0.0     0.0   \n",
       "2      0.0       0.0  ...  0.0  0.0  0.0  0.0      0.0     0.0     0.0   \n",
       "3      0.0       0.0  ...  0.0  0.0  0.0  0.0      0.0     0.0     0.0   \n",
       "4      0.0       0.0  ...  0.0  0.0  0.0  0.0      0.0     0.0     0.0   \n",
       "\n",
       "   zometa  zone  zoom  \n",
       "0     0.0   0.0   0.0  \n",
       "1     0.0   0.0   0.0  \n",
       "2     0.0   0.0   0.0  \n",
       "3     0.0   0.0   0.0  \n",
       "4     0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 7840 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_top = pd.DataFrame({'mean': df_reddit_tfidf.mean(), 'name': df_reddit_tfidf.columns}).sort_values('mean', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>0.033532</td>\n",
       "      <td>feel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>0.031709</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>0.031209</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>0.026339</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>0.025014</td>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.024566</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lump</th>\n",
       "      <td>0.024091</td>\n",
       "      <td>lump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>0.023975</td>\n",
       "      <td>doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.023475</td>\n",
       "      <td>find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>0.023171</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tell</th>\n",
       "      <td>0.022561</td>\n",
       "      <td>tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>take</th>\n",
       "      <td>0.022356</td>\n",
       "      <td>take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.021384</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>0.020766</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.020656</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain</th>\n",
       "      <td>0.020452</td>\n",
       "      <td>pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>0.020325</td>\n",
       "      <td>really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <td>0.020257</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>0.020203</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.019741</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>0.019439</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surgery</th>\n",
       "      <td>0.019301</td>\n",
       "      <td>surgery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>0.018819</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.018764</td>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>0.018156</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>0.018084</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leave</th>\n",
       "      <td>0.017814</td>\n",
       "      <td>leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>0.017644</td>\n",
       "      <td>come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>0.017455</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>0.017379</td>\n",
       "      <td>look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>0.017148</td>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stage</th>\n",
       "      <td>0.016927</td>\n",
       "      <td>stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ago</th>\n",
       "      <td>0.016563</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>0.016336</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>0.016239</td>\n",
       "      <td>need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mastectomy</th>\n",
       "      <td>0.016005</td>\n",
       "      <td>mastectomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom</th>\n",
       "      <td>0.015926</td>\n",
       "      <td>mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>0.015848</td>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>0.015827</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.015577</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side</th>\n",
       "      <td>0.015538</td>\n",
       "      <td>side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ultrasound</th>\n",
       "      <td>0.015499</td>\n",
       "      <td>ultrasound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemo</th>\n",
       "      <td>0.015446</td>\n",
       "      <td>chemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>0.015188</td>\n",
       "      <td>thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nipple</th>\n",
       "      <td>0.014985</td>\n",
       "      <td>nipple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiation</th>\n",
       "      <td>0.014979</td>\n",
       "      <td>radiation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biopsy</th>\n",
       "      <td>0.014955</td>\n",
       "      <td>biopsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>0.014606</td>\n",
       "      <td>still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>0.014604</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>try</th>\n",
       "      <td>0.014417</td>\n",
       "      <td>try</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean        name\n",
       "feel        0.033532        feel\n",
       "know        0.031709        know\n",
       "get         0.031209         get\n",
       "say         0.026339         say\n",
       "week        0.025014        week\n",
       "year        0.024566        year\n",
       "lump        0.024091        lump\n",
       "doctor      0.023975      doctor\n",
       "find        0.023475        find\n",
       "want        0.023171        want\n",
       "tell        0.022561        tell\n",
       "take        0.022356        take\n",
       "month       0.021384       month\n",
       "help        0.020766        help\n",
       "time        0.020656        time\n",
       "pain        0.020452        pain\n",
       "really      0.020325      really\n",
       "treatment   0.020257   treatment\n",
       "thank       0.020203       thank\n",
       "day         0.019741         day\n",
       "think       0.019439       think\n",
       "surgery     0.019301     surgery\n",
       "start       0.018819       start\n",
       "see         0.018764         see\n",
       "right       0.018156       right\n",
       "back        0.018084        back\n",
       "leave       0.017814       leave\n",
       "come        0.017644        come\n",
       "make        0.017455        make\n",
       "look        0.017379        look\n",
       "experience  0.017148  experience\n",
       "stage       0.016927       stage\n",
       "ago         0.016563         ago\n",
       "last        0.016336        last\n",
       "need        0.016239        need\n",
       "mastectomy  0.016005  mastectomy\n",
       "mom         0.015926         mom\n",
       "much        0.015848        much\n",
       "have        0.015827        have\n",
       "family      0.015577      family\n",
       "side        0.015538        side\n",
       "ultrasound  0.015499  ultrasound\n",
       "chemo       0.015446       chemo\n",
       "thing       0.015188       thing\n",
       "nipple      0.014985      nipple\n",
       "radiation   0.014979   radiation\n",
       "biopsy      0.014955      biopsy\n",
       "still       0.014606       still\n",
       "may         0.014604         may\n",
       "try         0.014417         try"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_top[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "k = 0\n",
    "for sen in df_tweets['text']:\n",
    "    if 'My name is fiza' in sen:\n",
    "        idx.append(k)\n",
    "    k += 1\n",
    "\n",
    "idx = idx[1:]\n",
    "for i in idx:\n",
    "    df_tweets = df_tweets.drop(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 1s, sys: 8.55 s, total: 5min 10s\n",
      "Wall time: 5min 13s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1314367341078228992</td>\n",
       "      <td>@lscreeden @ChicagoBears @BearsLocal @BearsOut...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>guy beautiful wife battle right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314371953906479104</td>\n",
       "      <td>ðŸŽ€ | PINKtober is HERE &amp;amp; Jessup ðŸ¥Ž canâ€™t wai...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wait new year long grab one percentage proceed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1314426946348957696</td>\n",
       "      <td>@HeelJonJones @Kuckaneer Heâ€™s talking about iz...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk tit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1314333474141151232</td>\n",
       "      <td>Join me and help change the future of breast c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>join change future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1314332965216882688</td>\n",
       "      <td>Sarah Harding is â€˜holding up wellâ€™ with mum Ma...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hold care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1314367341078228992  @lscreeden @ChicagoBears @BearsLocal @BearsOut...   \n",
       "1  1314371953906479104  ðŸŽ€ | PINKtober is HERE &amp; Jessup ðŸ¥Ž canâ€™t wai...   \n",
       "2  1314426946348957696  @HeelJonJones @Kuckaneer Heâ€™s talking about iz...   \n",
       "3  1314333474141151232  Join me and help change the future of breast c...   \n",
       "4  1314332965216882688  Sarah Harding is â€˜holding up wellâ€™ with mum Ma...   \n",
       "\n",
       "   class                                  preprocessed_text  \n",
       "0    0.0                guy beautiful wife battle right now  \n",
       "1    0.0  wait new year long grab one percentage proceed...  \n",
       "2    0.0                                           talk tit  \n",
       "3    0.0                                 join change future  \n",
       "4    0.0                                          hold care  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_tweets_clean = clean_data(df_tweets)\n",
    "df_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tweets = df_tweets_clean['preprocessed_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tweets = [x.split() for x in document_tweets]\n",
    "dct = Dictionary(document_tweets)  # fit dictionary\n",
    "corpus = [dct.doc2bow(line) for line in document_tweets]  # convert corpus to BoW format\n",
    "model = TfidfModel(corpus)  # fit model\n",
    "tfidf = model[corpus]\n",
    "tfidf_all = []\n",
    "for i in tfidf:\n",
    "    tfidf_all.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "d = defaultdict()\n",
    "for word_num in range(len(dct)):\n",
    "    if word_num % 5000 == 0:\n",
    "        print(word_num)\n",
    "    for sent in tfidf_all:\n",
    "            temp = [word for word in sent if word[0] == word_num]\n",
    "            if temp != [] and word_num in d:\n",
    "                d[word_num] += temp[0][1]\n",
    "            if word_num not in d:\n",
    "                d[word_num] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in d.items():\n",
    "        d[key] = value/len(tfidf)\n",
    "sss = []\n",
    "for word, idnum in dct.token2id.items():\n",
    "    sss.append([word, d[idnum]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_top = pd.DataFrame(sss, columns = ['name', 'mean']).sort_values('mean', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.016086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>year</td>\n",
       "      <td>0.013334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>help</td>\n",
       "      <td>0.013204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>awareness</td>\n",
       "      <td>0.012889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>get</td>\n",
       "      <td>0.012667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>month</td>\n",
       "      <td>0.011511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>say</td>\n",
       "      <td>0.011294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>know</td>\n",
       "      <td>0.010766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>treatment</td>\n",
       "      <td>0.010378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>die</td>\n",
       "      <td>0.009502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>mom</td>\n",
       "      <td>0.009105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.008899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>people</td>\n",
       "      <td>0.008857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>patient</td>\n",
       "      <td>0.008773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>pink</td>\n",
       "      <td>0.008676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>life</td>\n",
       "      <td>0.008620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>find</td>\n",
       "      <td>0.008584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>make</td>\n",
       "      <td>0.008376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>diagnose</td>\n",
       "      <td>0.008194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>matter</td>\n",
       "      <td>0.007974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fight</td>\n",
       "      <td>0.007951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>stage</td>\n",
       "      <td>0.007913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>man</td>\n",
       "      <td>0.007880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>survivor</td>\n",
       "      <td>0.007848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>thank</td>\n",
       "      <td>0.007683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>good</td>\n",
       "      <td>0.007587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>need</td>\n",
       "      <td>0.007579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>time</td>\n",
       "      <td>0.007475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>take</td>\n",
       "      <td>0.007266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new</td>\n",
       "      <td>0.007163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>research</td>\n",
       "      <td>0.006976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>early</td>\n",
       "      <td>0.006955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>mother</td>\n",
       "      <td>0.006948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>think</td>\n",
       "      <td>0.006917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>see</td>\n",
       "      <td>0.006910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>today</td>\n",
       "      <td>0.006816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>cell</td>\n",
       "      <td>0.006713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>check</td>\n",
       "      <td>0.006476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>study</td>\n",
       "      <td>0.006439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>day</td>\n",
       "      <td>0.006434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tell</td>\n",
       "      <td>0.006361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>family</td>\n",
       "      <td>0.006350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>live</td>\n",
       "      <td>0.006295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>surgery</td>\n",
       "      <td>0.006282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>friend</td>\n",
       "      <td>0.006133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>amp</td>\n",
       "      <td>0.006116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>lose</td>\n",
       "      <td>0.006114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>want</td>\n",
       "      <td>0.006095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>use</td>\n",
       "      <td>0.006074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>love</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name      mean\n",
       "41       woman  0.016086\n",
       "15        year  0.013334\n",
       "192       help  0.013204\n",
       "53   awareness  0.012889\n",
       "123        get  0.012667\n",
       "77       month  0.011511\n",
       "288        say  0.011294\n",
       "219       know  0.010766\n",
       "166  treatment  0.010378\n",
       "234        die  0.009502\n",
       "221        mom  0.009105\n",
       "34        risk  0.008899\n",
       "380     people  0.008857\n",
       "49     patient  0.008773\n",
       "62        pink  0.008676\n",
       "356       life  0.008620\n",
       "122       find  0.008584\n",
       "330       make  0.008376\n",
       "423   diagnose  0.008194\n",
       "39      matter  0.007974\n",
       "79       fight  0.007951\n",
       "226      stage  0.007913\n",
       "339        man  0.007880\n",
       "230   survivor  0.007848\n",
       "186      thank  0.007683\n",
       "115       good  0.007587\n",
       "300       need  0.007579\n",
       "85        time  0.007475\n",
       "164       take  0.007266\n",
       "9          new  0.007163\n",
       "13    research  0.006976\n",
       "121      early  0.006955\n",
       "82      mother  0.006948\n",
       "879      think  0.006917\n",
       "64         see  0.006910\n",
       "253      today  0.006816\n",
       "583       cell  0.006713\n",
       "361      check  0.006476\n",
       "499      study  0.006439\n",
       "212        day  0.006434\n",
       "165       tell  0.006361\n",
       "28      family  0.006350\n",
       "153       live  0.006295\n",
       "196    surgery  0.006282\n",
       "30      friend  0.006133\n",
       "453        amp  0.006116\n",
       "728       lose  0.006114\n",
       "167       want  0.006095\n",
       "421        use  0.006074\n",
       "125       love  0.006071"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_top[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41         woman\n",
       "15          year\n",
       "192         help\n",
       "53     awareness\n",
       "123          get\n",
       "77         month\n",
       "288          say\n",
       "219         know\n",
       "166    treatment\n",
       "234          die\n",
       "221          mom\n",
       "34          risk\n",
       "380       people\n",
       "49       patient\n",
       "62          pink\n",
       "356         life\n",
       "122         find\n",
       "330         make\n",
       "423     diagnose\n",
       "39        matter\n",
       "79         fight\n",
       "226        stage\n",
       "339          man\n",
       "230     survivor\n",
       "186        thank\n",
       "115         good\n",
       "300         need\n",
       "85          time\n",
       "164         take\n",
       "9            new\n",
       "13      research\n",
       "121        early\n",
       "82        mother\n",
       "879        think\n",
       "64           see\n",
       "253        today\n",
       "583         cell\n",
       "361        check\n",
       "499        study\n",
       "212          day\n",
       "165         tell\n",
       "28        family\n",
       "153         live\n",
       "196      surgery\n",
       "30        friend\n",
       "453          amp\n",
       "728         lose\n",
       "167         want\n",
       "421          use\n",
       "125         love\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_top.iloc[:50, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Data Analysis Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.5 s, sys: 31.6 s, total: 1min 28s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "document_tweets_1 = df_tweets_clean.loc[df_tweets_clean['class']==1, 'preprocessed_text'].tolist()\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(document_tweets_1)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df_tweets_tfidf_1 = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_top_1 = pd.DataFrame({'mean': df_tweets_tfidf_1.mean(), 'name': df_tweets_tfidf_1.columns}).sort_values('mean', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.032388</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>0.022207</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survivor</th>\n",
       "      <td>0.018603</td>\n",
       "      <td>survivor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stage</th>\n",
       "      <td>0.017863</td>\n",
       "      <td>stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <td>0.017130</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surgery</th>\n",
       "      <td>0.015366</td>\n",
       "      <td>surgery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>0.015325</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>0.015079</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>0.014902</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.014709</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>take</th>\n",
       "      <td>0.013866</td>\n",
       "      <td>take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.013451</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.013425</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ago</th>\n",
       "      <td>0.013035</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>0.012291</td>\n",
       "      <td>need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.012054</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>0.012035</td>\n",
       "      <td>still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnose</th>\n",
       "      <td>0.011853</td>\n",
       "      <td>diagnose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.011652</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fight</th>\n",
       "      <td>0.011548</td>\n",
       "      <td>fight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>0.011344</td>\n",
       "      <td>feel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>0.011269</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>0.011135</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.010969</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.010507</td>\n",
       "      <td>find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>0.010347</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>0.010226</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>0.009842</td>\n",
       "      <td>amp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tell</th>\n",
       "      <td>0.009716</td>\n",
       "      <td>tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>0.009652</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>0.009411</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosed</th>\n",
       "      <td>0.009376</td>\n",
       "      <td>diagnosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>0.009163</td>\n",
       "      <td>never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>0.009048</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0.009019</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>live</th>\n",
       "      <td>0.008997</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>0.008850</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>0.008849</td>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>0.008836</td>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>0.008798</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>give</th>\n",
       "      <td>0.008789</td>\n",
       "      <td>give</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.008675</td>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>0.008598</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemo</th>\n",
       "      <td>0.008483</td>\n",
       "      <td>chemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>0.008419</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metastatic</th>\n",
       "      <td>0.008397</td>\n",
       "      <td>metastatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>0.008340</td>\n",
       "      <td>come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survive</th>\n",
       "      <td>0.008134</td>\n",
       "      <td>survive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep</th>\n",
       "      <td>0.008010</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.007910</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean        name\n",
       "year        0.032388        year\n",
       "get         0.022207         get\n",
       "survivor    0.018603    survivor\n",
       "stage       0.017863       stage\n",
       "treatment   0.017130   treatment\n",
       "surgery     0.015366     surgery\n",
       "know        0.015325        know\n",
       "help        0.015079        help\n",
       "thank       0.014902       thank\n",
       "life        0.014709        life\n",
       "take        0.013866        take\n",
       "good        0.013451        good\n",
       "time        0.013425        time\n",
       "ago         0.013035         ago\n",
       "need        0.012291        need\n",
       "love        0.012054        love\n",
       "still       0.012035       still\n",
       "diagnose    0.011853    diagnose\n",
       "day         0.011652         day\n",
       "fight       0.011548       fight\n",
       "feel        0.011344        feel\n",
       "make        0.011269        make\n",
       "say         0.011135         say\n",
       "month       0.010969       month\n",
       "find        0.010507        find\n",
       "today       0.010347       today\n",
       "last        0.010226        last\n",
       "amp         0.009842         amp\n",
       "tell        0.009716        tell\n",
       "have        0.009652        have\n",
       "well        0.009411        well\n",
       "diagnosed   0.009376   diagnosed\n",
       "never       0.009163       never\n",
       "think       0.009048       think\n",
       "work        0.009019        work\n",
       "live        0.008997        live\n",
       "back        0.008850        back\n",
       "week        0.008849        week\n",
       "much        0.008836        much\n",
       "people      0.008798      people\n",
       "give        0.008789        give\n",
       "see         0.008675         see\n",
       "want        0.008598        want\n",
       "chemo       0.008483       chemo\n",
       "free        0.008419        free\n",
       "metastatic  0.008397  metastatic\n",
       "come        0.008340        come\n",
       "survive     0.008134     survive\n",
       "keep        0.008010        keep\n",
       "woman       0.007910       woman"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_top_1[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Data Analysis Class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tweets_0 = df_tweets_clean.loc[df_tweets_clean['class']==0, 'preprocessed_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tweets_0 = [x.split() for x in document_tweets_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct0 = Dictionary(document_tweets_0)  # fit dictionary\n",
    "corpus0 = [dct0.doc2bow(line) for line in document_tweets_0]  # convert corpus to BoW format\n",
    "model0 = TfidfModel(corpus0)  # fit model\n",
    "tfidf0 = model0[corpus0]\n",
    "tfidf_all0 = []\n",
    "for i in tfidf0:\n",
    "    tfidf_all0.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "d0 = defaultdict()\n",
    "for word_num in range(len(dct0.token2id)):\n",
    "    if word_num%5000 == 0:\n",
    "        print(word_num)\n",
    "    for sent in tfidf_all0:\n",
    "            temp = [word for word in sent if word[0] == word_num]\n",
    "            if temp != [] and word_num in d0:\n",
    "                d0[word_num] += temp[0][1]\n",
    "            if word_num not in d0:\n",
    "                d0[word_num] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in d0.items():\n",
    "        d0[key] = value/len(tfidf_all0)\n",
    "sss0 = []\n",
    "for word, idnum in dct0.token2id.items():\n",
    "    sss0.append([word, d0[idnum]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_top_0 = pd.DataFrame(sss0, columns = ['name', 'mean']).sort_values('mean', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.016860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>awareness</td>\n",
       "      <td>0.013797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>help</td>\n",
       "      <td>0.013331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>get</td>\n",
       "      <td>0.012064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>month</td>\n",
       "      <td>0.011803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>year</td>\n",
       "      <td>0.011683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>say</td>\n",
       "      <td>0.011527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>know</td>\n",
       "      <td>0.010559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>treatment</td>\n",
       "      <td>0.009984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>die</td>\n",
       "      <td>0.009831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>mom</td>\n",
       "      <td>0.009486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.009416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>pink</td>\n",
       "      <td>0.009277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>patient</td>\n",
       "      <td>0.009131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>people</td>\n",
       "      <td>0.009017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>matter</td>\n",
       "      <td>0.008573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>find</td>\n",
       "      <td>0.008567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>man</td>\n",
       "      <td>0.008397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>make</td>\n",
       "      <td>0.008272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>life</td>\n",
       "      <td>0.008205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>diagnose</td>\n",
       "      <td>0.007961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fight</td>\n",
       "      <td>0.007730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new</td>\n",
       "      <td>0.007507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>research</td>\n",
       "      <td>0.007487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>mother</td>\n",
       "      <td>0.007335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>cell</td>\n",
       "      <td>0.007288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>need</td>\n",
       "      <td>0.007253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>early</td>\n",
       "      <td>0.007142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>good</td>\n",
       "      <td>0.007117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>thank</td>\n",
       "      <td>0.007058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>time</td>\n",
       "      <td>0.007003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>study</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>stage</td>\n",
       "      <td>0.006959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>see</td>\n",
       "      <td>0.006852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>think</td>\n",
       "      <td>0.006805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>survivor</td>\n",
       "      <td>0.006787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>take</td>\n",
       "      <td>0.006719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>check</td>\n",
       "      <td>0.006686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>today</td>\n",
       "      <td>0.006588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>raise</td>\n",
       "      <td>0.006447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>family</td>\n",
       "      <td>0.006279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>friend</td>\n",
       "      <td>0.006264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>use</td>\n",
       "      <td>0.006150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>live</td>\n",
       "      <td>0.006139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>screening</td>\n",
       "      <td>0.006109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>tell</td>\n",
       "      <td>0.006099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>lose</td>\n",
       "      <td>0.006036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>day</td>\n",
       "      <td>0.006003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>want</td>\n",
       "      <td>0.005928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>amp</td>\n",
       "      <td>0.005853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name      mean\n",
       "41       woman  0.016860\n",
       "53   awareness  0.013797\n",
       "184       help  0.013331\n",
       "123        get  0.012064\n",
       "77       month  0.011803\n",
       "15        year  0.011683\n",
       "271        say  0.011527\n",
       "211       know  0.010559\n",
       "405  treatment  0.009984\n",
       "226        die  0.009831\n",
       "213        mom  0.009486\n",
       "34        risk  0.009416\n",
       "62        pink  0.009277\n",
       "49     patient  0.009131\n",
       "364     people  0.009017\n",
       "39      matter  0.008573\n",
       "122       find  0.008567\n",
       "323        man  0.008397\n",
       "313       make  0.008272\n",
       "340       life  0.008205\n",
       "408   diagnose  0.007961\n",
       "79       fight  0.007730\n",
       "9          new  0.007507\n",
       "13    research  0.007487\n",
       "82      mother  0.007335\n",
       "572       cell  0.007288\n",
       "283       need  0.007253\n",
       "121      early  0.007142\n",
       "115       good  0.007117\n",
       "178      thank  0.007058\n",
       "85        time  0.007003\n",
       "486      study  0.006993\n",
       "218      stage  0.006959\n",
       "64         see  0.006852\n",
       "850      think  0.006805\n",
       "222   survivor  0.006787\n",
       "256       take  0.006719\n",
       "345      check  0.006686\n",
       "245      today  0.006588\n",
       "155      raise  0.006447\n",
       "28      family  0.006279\n",
       "30      friend  0.006264\n",
       "406        use  0.006150\n",
       "153       live  0.006139\n",
       "277  screening  0.006109\n",
       "532       tell  0.006099\n",
       "712       lose  0.006036\n",
       "204        day  0.006003\n",
       "638       want  0.005928\n",
       "439        amp  0.005853"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_top_0[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41               woman\n",
       "53           awareness\n",
       "184               help\n",
       "123                get\n",
       "77               month\n",
       "15                year\n",
       "271                say\n",
       "211               know\n",
       "405          treatment\n",
       "226                die\n",
       "213                mom\n",
       "34                risk\n",
       "62                pink\n",
       "49             patient\n",
       "364             people\n",
       "39              matter\n",
       "122               find\n",
       "323                man\n",
       "313               make\n",
       "340               life\n",
       "408           diagnose\n",
       "79               fight\n",
       "9                  new\n",
       "13            research\n",
       "82              mother\n",
       "572               cell\n",
       "283               need\n",
       "121              early\n",
       "115               good\n",
       "178              thank\n",
       "             ...      \n",
       "2277             sound\n",
       "2802           mention\n",
       "149              claim\n",
       "613              virus\n",
       "722             choose\n",
       "844            protect\n",
       "400              power\n",
       "2557          chemical\n",
       "209                hit\n",
       "1457           comment\n",
       "160               bear\n",
       "3914              dose\n",
       "983                ill\n",
       "1509           inspire\n",
       "760               sick\n",
       "310              drink\n",
       "2222            immune\n",
       "3347           project\n",
       "3523          analysis\n",
       "1721              fine\n",
       "1214           partner\n",
       "1014             birth\n",
       "1772         yesterday\n",
       "3668           implant\n",
       "2005             bccww\n",
       "1663           auction\n",
       "2217          specific\n",
       "3942            cancel\n",
       "1829            urgent\n",
       "50      reconstruction\n",
       "Name: name, Length: 559, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_top_0.loc[:50, \"name\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
